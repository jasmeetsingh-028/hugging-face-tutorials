{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image-text retrieval/matching (Multimodal)"
      ],
      "metadata": {
        "id": "7m4A9J9ZLoeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWhh--_KK-XO"
      },
      "outputs": [],
      "source": [
        "#similarity between text string and the image\n",
        "#Multimodal models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the blip model\n",
        "from transformers import BlipForImageTextRetrieval\n",
        "\n",
        "model = BlipForImageTextRetrieval.from_pretrained(\n",
        "    \"Salesforce/blip-itm-base-coco\"\n",
        ")\n",
        "#895M"
      ],
      "metadata": {
        "id": "qWUA96qqLqud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading autoprocessor\n",
        "\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"Salesforce/blip-itm-base-coco\"\n",
        ")"
      ],
      "metadata": {
        "id": "nNMuxevnN8Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing image\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open('Image1.png')\n",
        "image"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NZDBOYaoOfHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#string for image and string matching\n",
        "\n",
        "string = \"A soccer player on the field\""
      ],
      "metadata": {
        "id": "rYakZVsPOzQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images = image,\n",
        "                   text = string,\n",
        "                   return_tensors  = 'pt')"
      ],
      "metadata": {
        "id": "_lMno3_qPEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matching_scores = model(**inputs)[0]"
      ],
      "metadata": {
        "id": "YP-P0nGGPOaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matching_scores  ##applying softmax layer to ouput logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRbnDGFgPV2y",
        "outputId": "afe262b9-d7fa-4230-d617-3e14924a0363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5146,  0.5116]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "softmax_scores = torch.nn.functional.softmax(\n",
        "    matching_scores,\n",
        "    dim=1\n",
        ")\n",
        "softmax_scores\n",
        "\n",
        "print(f'image and text are matched with probablity: {softmax_scores[0][1]:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aay-gZVbPdnb",
        "outputId": "72670893-6d4b-412a-8c05-11ab2c2c5f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image and text are matched with probablity: 0.7362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image-Captioning with Blip (different weights used)"
      ],
      "metadata": {
        "id": "NSNcGQ7MQkLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipForConditionalGeneration\n",
        "\n",
        "model = BlipForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/blip-image-captioning-base\"\n",
        ")\n",
        "#990M"
      ],
      "metadata": {
        "id": "Q4HVueBVPvYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading autoprocessor\n",
        "\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"Salesforce/blip-image-captioning-base\"\n",
        ")"
      ],
      "metadata": {
        "id": "0hmZbJleRAgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##using the same image\n",
        "##performing conditional image captioning- pass text that will the start of the output of the model\n",
        "\n",
        "text = \"a photograph of\"\n",
        "inputs = processor(image, text,\n",
        "                  return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "xWQqtW_wRJER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZXY-X8KrSUEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(**inputs) #souble stars as it is a dictionary of arguments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqNh4M6GSaV4",
        "outputId": "f48f0067-220c-4585-da45-73c035553c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output  ##ouput are token ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onO01OvaSoFR",
        "outputId": "cd60e2dc-6610-4a80-d1e3-e5ab71afc3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[30522,  1037,  9982,  1997,  1037,  4715,  2447,  2770,  2006,  1996,\n",
              "          2492,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor.decode(output[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FEl8yDbgUaN7",
        "outputId": "28898908-b8ed-4739-9f79-4beb5de3293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a photograph of a soccer player running on the field'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating text without conditioning"
      ],
      "metadata": {
        "id": "dLbroiktVhif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(image, return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "bGiNEOwsUpae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(**inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HCCMmS0W1_G",
        "outputId": "0e2bacba-f83f-4f29-94b6-812eda0933a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output\n",
        "processor.decode(output[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oOBhllEGW59d",
        "outputId": "6178fe77-19a2-4201-9f9c-993a3415e53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a man running on a soccer field'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}